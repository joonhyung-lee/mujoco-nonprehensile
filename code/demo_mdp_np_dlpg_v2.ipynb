{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a RL Environment about `Non-prehensile task` on table-top scene training with `Deep Latent Policy Gradient`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version:[1.13.1+cu116]\n",
      "MuJoCo version:[2.3.4]\n"
     ]
    }
   ],
   "source": [
    "import mujoco,torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mujoco_parser import MuJoCoParserClass\n",
    "from util import r2rpy, sample_xyzs\n",
    "from np_env import NonPrehensileMarkovDecisionProcessClass\n",
    "np.set_printoptions(precision=2,suppress=True,linewidth=100)\n",
    "plt.rc('xtick',labelsize=6); plt.rc('ytick',labelsize=6)\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "print (\"Torch version:[%s]\"%(torch.__version__))\n",
    "print (\"MuJoCo version:[%s]\"%(mujoco.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse `UR5e`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[UR5e] Instantiated\n",
      "   [info] dt:[0.0200] HZ:[50], env-HZ:[500], mujoco_nstep:[10], state_dim:[26], o_dim:[260], a_dim:[7]\n",
      "   [history] total_sec:[1.00]sec, n:[50], intv_sec:[0.10]sec, intv_tick:[5]\n",
      "   [history] ticks:[ 0  5 10 15 20 25 30 35 40 45]\n",
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "xml_path = '../asset/ur5e/scene_ur5e_rg2_obj.xml'\n",
    "env = MuJoCoParserClass(name='UR5e',rel_xml_path=xml_path,VERBOSE=False)\n",
    "# Instantiate MDP\n",
    "mdp = NonPrehensileMarkovDecisionProcessClass(env,HZ=50,history_total_sec=1.0,history_intv_sec=0.1,VERBOSE=True)\n",
    "\n",
    "obj_names = [body_name for body_name in env.body_names\n",
    "             if body_name is not None and (body_name.startswith(\"obj_\"))]\n",
    "n_obj = len(obj_names)\n",
    "# Place objects\n",
    "xyzs = sample_xyzs(n_sample=n_obj,\n",
    "                   x_range=[0.72,0.95],y_range=[-0.38,0.38],z_range=[0.81,0.81],min_dist=0.2)\n",
    "colors = np.array([plt.cm.gist_rainbow(x) for x in np.linspace(0,1,n_obj)])\n",
    "for obj_idx,obj_name in enumerate(obj_names):\n",
    "    jntadr = env.model.body(obj_name).jntadr[0]\n",
    "    env.model.joint(jntadr).qpos0[:3] = xyzs[obj_idx,:]\n",
    "    geomadr = env.model.body(obj_name).geomadr[0]\n",
    "    env.model.geom(geomadr).rgba = colors[obj_idx] # color\n",
    "\n",
    "# Move tables and robot base\n",
    "env.model.body('base_table').pos = np.array([0,0,0])\n",
    "env.model.body('front_object_table').pos = np.array([1.05,0,0])\n",
    "env.model.body('side_object_table').pos = np.array([0,-0.85,0])\n",
    "env.model.body('base').pos = np.array([0,0,0.8])\n",
    "print (\"Ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mdp.env.ctrl_ranges:\n",
      " [[-2.  2.]\n",
      " [-2.  2.]\n",
      " [-2.  2.]\n",
      " [-2.  2.]\n",
      " [-2.  2.]\n",
      " [-2.  2.]\n",
      " [-2.  2.]]\n"
     ]
    }
   ],
   "source": [
    "max_torque = 2\n",
    "mdp.env.ctrl_ranges[:,0] = -max_torque\n",
    "mdp.env.ctrl_ranges[:,1] = +max_torque\n",
    "print (\"mdp.env.ctrl_ranges:\\n\",mdp.env.ctrl_ranges)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate `DLPG` model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import random as rd \n",
    "import math \n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import wandb\n",
    "import sys \n",
    "# from pathlib import Path\n",
    "# BASEDIR = str(Path(__file__).parent)\n",
    "# sys.path.append(BASEDIR)\n",
    "sys.path.append('..')\n",
    "\n",
    "from model.dlpg.dlpg import DeepLatentPolicyGradient\n",
    "from model.dlpg.buffer import BufferClass\n",
    "from model.utils import torch2np, np2torch, kernel_se, kernel_levse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 122500\n"
     ]
    }
   ],
   "source": [
    "training_data = [json.loads(line) for line in open('./json/np_buffer_v1.json', 'r')]\n",
    "print(\"Total: {}\".format(len(training_data)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample-Method:uniform\n",
      "Device cuda:0\n",
      "Model Instance.\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample-Method:{}\".format('uniform'))\n",
    "# Set random seed \n",
    "random_seed = 42\n",
    "np.random.seed(random_seed)\n",
    "rd.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Device\", device)\n",
    "buffer = BufferClass(xdim=9, cdim=72, buffer_limit=len(training_data), device=device)\n",
    "for idx, data in enumerate(training_data): \n",
    "    buffer.store(x=np.array(data[\"x\"]).reshape(-1), c=data[\"c\"], reward=data[\"reward\"])\n",
    "\n",
    "DLPG = DeepLatentPolicyGradient(xdim     = 9,\n",
    "                                cdim     = 72,\n",
    "                                zdim     = 2,\n",
    "                                hdims    = [128],\n",
    "                                actv_enc = nn.LeakyReLU(),\n",
    "                                actv_dec = None,#nn.LeakyReLU(), \n",
    "                                actv_out = nn.Tanh(), \n",
    "                                actv_q   = nn.Softplus(),\n",
    "                                device   = device)\n",
    "# DLPG.cvae.load_state_dict(torch.load(weight_path))\n",
    "optimizer = torch.optim.Adam(params=DLPG.cvae.parameters(),lr=0.001,betas=(0.9,0.99),eps=1e-4)\n",
    "\n",
    "print(\"Model Instance.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 100\n",
    "batch_size = 128\n",
    "epsgrdy = 0.1\n",
    "\n",
    "# wandb.init(project=\"dlpg\", entity=\"dlpg\")\n",
    "# wandb.config.max_epochs = max_epochs\n",
    "# wandb.config.batch_size = batch_size\n",
    "\n",
    "eval_epochs = 10\n",
    "n_sample = 10\n",
    "RENDER = True\n",
    "WANDB = False\n",
    "update_every = 1\n",
    "MAXITER = 1000\n",
    "sample_method = 'uniform'\n",
    "runname = 'none'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_spawn(env, obj_names, x_range=[0.72,0.95],y_range=[-0.38,0.38],z_range=[0.81,0.81],min_dist=0.2):\n",
    "    \"\"\"\n",
    "        Obstacle random spawn \n",
    "    \"\"\"\n",
    "    n_obj = len(obj_names)\n",
    "    # Place objects\n",
    "    xyzs = sample_xyzs(n_sample=n_obj,\n",
    "                    x_range=x_range,y_range=y_range,z_range=z_range,min_dist=min_dist)\n",
    "    colors = np.array([plt.cm.gist_rainbow(x) for x in np.linspace(0,1,n_obj)])\n",
    "    for obj_idx,obj_name in enumerate(obj_names):\n",
    "        jntadr = env.model.body(obj_name).jntadr[0]\n",
    "        env.model.joint(jntadr).qpos0[:3] = xyzs[obj_idx,:]\n",
    "        geomadr = env.model.body(obj_name).geomadr[0]\n",
    "        env.model.geom(geomadr).rgba = colors[obj_idx] # color\n",
    "\n",
    "    return xyzs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import rpy2r\n",
    "\n",
    "# Init viewer\n",
    "env.init_viewer(viewer_title='UR5e with RG2 gripper',viewer_width=1200,viewer_height=800,\n",
    "                viewer_hide_menus=True)\n",
    "env.update_viewer(azimuth=66.08,distance=3.0,elevation=-50,lookat=[0.4,0.18,0.71],\n",
    "                  VIS_TRANSPARENT=False,VIS_CONTACTPOINT=False,\n",
    "                  contactwidth=0.05,contactheight=0.05,contactrgba=np.array([1,0,0,1]),\n",
    "                  VIS_JOINT=True,jointlength=0.25,jointwidth=0.05,jointrgba=[0.2,0.6,0.8,0.6])\n",
    "\n",
    "# Base pose\n",
    "body_name = 'tcp_link'\n",
    "p_base = env.get_p_body(body_name='base')\n",
    "R_trgt = rpy2r(np.radians([0,0,0]))@rpy2r(np.radians([-180,0,90]))\n",
    "\n",
    "# Straight pose\n",
    "DO_RENDER_IK = True\n",
    "init_configurations = [-0.73418, -1.08485, 2.7836, -1.699, 0.8366, 0]\n",
    "R_trgt = rpy2r(np.radians([-180,0,90]))\n",
    "# init_configurations = np.array([np.deg2rad(-90), np.deg2rad(-132.46), np.deg2rad(122.85), np.deg2rad(99.65), np.deg2rad(45), np.deg2rad(-90.02)])\n",
    "env.forward(q=init_configurations,joint_idxs=env.idxs_forward)\n",
    "q_ik_list = []\n",
    "\n",
    "for (x_trgt, y_trgt) in zip(t_test, mean_traj):\n",
    "    print(f\"(x_trgt, y_trgt, z_trgt): ({x_trgt}, {y_trgt}, {0.81})\")\n",
    "    q_ik = env.solve_ik(\n",
    "        body_name=body_name, p_trgt=np.array([x_trgt[0], y_trgt[0], 0.86]), R_trgt=R_trgt, IK_P=True, IK_R=True,\n",
    "        q_init=init_configurations, idxs_forward=env.idxs_forward, idxs_jacobian=env.idxs_jacobian,\n",
    "        RESET=False, DO_RENDER=DO_RENDER_IK, render_every=1, th=1*np.pi/180.0, err_th=1e-4)\n",
    "    q_ik_list.append(q_ik)\n",
    "\n",
    "q_ik_list = np.array(q_ik_list)\n",
    "q_ik_list[:, -2] = 1.47\n",
    "print(q_ik_list)\n",
    "\n",
    "# Close viewer\n",
    "env.close_viewer()\n",
    "print (\"Done. Tick:[%d] Time:[%.2f]sec\"%(env.tick,env.get_sim_time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rpy2r' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m R_trgt \u001b[39m=\u001b[39m rpy2r(np\u001b[39m.\u001b[39mradians([\u001b[39m-\u001b[39m\u001b[39m180\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m180\u001b[39m]))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rpy2r' is not defined"
     ]
    }
   ],
   "source": [
    "R_trgt = rpy2r(np.radians([-180,0,180]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import rpy2r\n",
    "\n",
    "# Base pose\n",
    "body_name = 'tcp_link'\n",
    "p_base = env.get_p_body(body_name='base')\n",
    "# R_trgt = rpy2r(np.radians([0,0,0]))@rpy2r(np.radians([-180,0,90]))\n",
    "\n",
    "# Straight pose\n",
    "init_configurations = [-0.73418, -1.08485, 2.7836, -1.699, 0.8366, 0]\n",
    "R_trgt = rpy2r(np.radians([-180,0,90]))\n",
    "# init_configurations = np.array([np.deg2rad(-90), np.deg2rad(-132.46), np.deg2rad(122.85), np.deg2rad(99.65), np.deg2rad(45), np.deg2rad(-90.02)])\n",
    "env.forward(q=init_configurations,joint_idxs=env.idxs_forward)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 1]\n",
      "Explore: (x_trgt, y_trgt, z_trgt): ([0.65], [0.], 0.9)\n",
      "Explore: (x_trgt, y_trgt, z_trgt): ([0.71], [0.01], 0.9)\n",
      "Explore: (x_trgt, y_trgt, z_trgt): ([0.76], [0.04], 0.9)\n",
      "Explore: (x_trgt, y_trgt, z_trgt): ([0.82], [0.08], 0.9)\n",
      "Explore: (x_trgt, y_trgt, z_trgt): ([0.87], [0.13], 0.9)\n",
      "Explore: (x_trgt, y_trgt, z_trgt): ([0.93], [0.18], 0.9)\n",
      "Explore: (x_trgt, y_trgt, z_trgt): ([0.98], [0.23], 0.9)\n",
      "Explore: (x_trgt, y_trgt, z_trgt): ([1.04], [0.28], 0.9)\n",
      "Explore: (x_trgt, y_trgt, z_trgt): ([1.09], [0.32], 0.9)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 59\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39mfor\u001b[39;00m _, (x, y) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mzip\u001b[39m(t_test, traj)):\n\u001b[1;32m     58\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExplore: (x_trgt, y_trgt, z_trgt): (\u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{\u001b[39;00my\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m0.9\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 59\u001b[0m     q \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49msolve_ik(\n\u001b[1;32m     60\u001b[0m         body_name\u001b[39m=\u001b[39;49mbody_name, p_trgt\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49marray([x[\u001b[39m0\u001b[39;49m], y[\u001b[39m0\u001b[39;49m], \u001b[39m0.9\u001b[39;49m]), R_trgt\u001b[39m=\u001b[39;49mR_trgt, IK_P\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, IK_R\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     61\u001b[0m         q_init\u001b[39m=\u001b[39;49minit_configurations, idxs_forward\u001b[39m=\u001b[39;49menv\u001b[39m.\u001b[39;49midxs_forward, idxs_jacobian\u001b[39m=\u001b[39;49menv\u001b[39m.\u001b[39;49midxs_jacobian,\n\u001b[1;32m     62\u001b[0m         RESET\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, DO_RENDER\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, render_every\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, th\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m\u001b[39m*\u001b[39;49mnp\u001b[39m.\u001b[39;49mpi\u001b[39m/\u001b[39;49m\u001b[39m180.0\u001b[39;49m, err_th\u001b[39m=\u001b[39;49m\u001b[39m1e-4\u001b[39;49m)\n\u001b[1;32m     63\u001b[0m     \u001b[39m# Make a trajectory by adding q values in every step.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m     \u001b[39m# q = env.solve_ik(P_EE_des=np.array([x, y, 0.9], dtype=object), \u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[39m#                     R_EE_des=np.array([-math.pi, 0, math.pi], dtype=object))\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     q_trajs\u001b[39m.\u001b[39mappend(q)\n",
      "File \u001b[0;32m~/python/QD/mujoco-nonprehensile/code/mujoco_parser.py:421\u001b[0m, in \u001b[0;36mMuJoCoParserClass.solve_ik\u001b[0;34m(self, body_name, p_trgt, R_trgt, IK_P, IK_R, q_init, idxs_forward, idxs_jacobian, RESET, DO_RENDER, render_every, th, err_th, w_weight)\u001b[0m\n\u001b[1;32m    418\u001b[0m tick \u001b[39m=\u001b[39m tick \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    419\u001b[0m J,err \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_ik_ingredients(\n\u001b[1;32m    420\u001b[0m     body_name\u001b[39m=\u001b[39mbody_name,p_trgt\u001b[39m=\u001b[39mp_trgt,R_trgt\u001b[39m=\u001b[39mR_trgt,IK_P\u001b[39m=\u001b[39mIK_P,IK_R\u001b[39m=\u001b[39mIK_R, w_weight\u001b[39m=\u001b[39mw_weight)\n\u001b[0;32m--> 421\u001b[0m dq \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdamped_ls(J,err,stepsize\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,eps\u001b[39m=\u001b[39;49m\u001b[39m1e-1\u001b[39;49m,th\u001b[39m=\u001b[39;49mth)\n\u001b[1;32m    422\u001b[0m q \u001b[39m=\u001b[39m q \u001b[39m+\u001b[39m dq[idxs_jacobian]\n\u001b[1;32m    423\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward(q\u001b[39m=\u001b[39mq,joint_idxs\u001b[39m=\u001b[39midxs_forward)\n",
      "File \u001b[0;32m~/python/QD/mujoco-nonprehensile/code/mujoco_parser.py:386\u001b[0m, in \u001b[0;36mMuJoCoParserClass.damped_ls\u001b[0;34m(self, J, err, eps, stepsize, th)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdamped_ls\u001b[39m(\u001b[39mself\u001b[39m,J,err,eps\u001b[39m=\u001b[39m\u001b[39m1e-6\u001b[39m,stepsize\u001b[39m=\u001b[39m\u001b[39m1.0\u001b[39m,th\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m\u001b[39m*\u001b[39mnp\u001b[39m.\u001b[39mpi\u001b[39m/\u001b[39m\u001b[39m180.0\u001b[39m):\n\u001b[1;32m    383\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    384\u001b[0m \u001b[39m        Dampled least square for IK\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 386\u001b[0m     dq \u001b[39m=\u001b[39m stepsize\u001b[39m*\u001b[39mnp\u001b[39m.\u001b[39;49mlinalg\u001b[39m.\u001b[39;49msolve(a\u001b[39m=\u001b[39;49m(J\u001b[39m.\u001b[39;49mT\u001b[39m@J\u001b[39;49m)\u001b[39m+\u001b[39;49meps\u001b[39m*\u001b[39;49mnp\u001b[39m.\u001b[39;49meye(J\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m]),b\u001b[39m=\u001b[39;49mJ\u001b[39m.\u001b[39;49mT\u001b[39m@err\u001b[39;49m)\n\u001b[1;32m    387\u001b[0m     dq \u001b[39m=\u001b[39m trim_scale(x\u001b[39m=\u001b[39mdq,th\u001b[39m=\u001b[39mth)\n\u001b[1;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m dq\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36msolve\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/linalg/linalg.py:386\u001b[0m, in \u001b[0;36msolve\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m    384\u001b[0m signature \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mDD->D\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m isComplexType(t) \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mdd->d\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    385\u001b[0m extobj \u001b[39m=\u001b[39m get_linalg_error_extobj(_raise_linalgerror_singular)\n\u001b[0;32m--> 386\u001b[0m r \u001b[39m=\u001b[39m gufunc(a, b, signature\u001b[39m=\u001b[39;49msignature, extobj\u001b[39m=\u001b[39;49mextobj)\n\u001b[1;32m    388\u001b[0m \u001b[39mreturn\u001b[39;00m wrap(r\u001b[39m.\u001b[39mastype(result_t, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train\n",
    "for epoch in range(max_epochs):\n",
    "    print(\"[Epoch: {}]\".format(epoch+1))\n",
    "    \"\"\" ROLLOUT \"\"\"\n",
    "    env.reset()\n",
    "    # Ranodm spawn\n",
    "    goal_position  = np.random.uniform(-0.1, 0.1) \n",
    "    # random_obs = env.random_pose(goal_position=goal_position)\n",
    "    random_obs = random_spawn(env, obj_names, x_range=[0.72,0.95],y_range=[-0.38,0.38],z_range=[0.81,0.81],min_dist=0.2)\n",
    "    \n",
    "    # Get a conditional vector\n",
    "    c_np           = np.array(random_obs).reshape(-1)\n",
    "    c_np           = np.append(c_np, goal_position) # [(x,y) x n + 1 (y axis of goal posiiton)]\n",
    "    c              = np2torch(c_np, device=device).reshape(1,-1)\n",
    "    # Epsgrdy\n",
    "    EXPLORE        = 1/10**(epoch/epsgrdy)   \n",
    "    EXPLOIT        = np.random.rand() > EXPLORE \n",
    "    # Exploit [Posterior sampling]\n",
    "    if EXPLOIT:\n",
    "        z                              = torch.randn(size=(1, DLPG.zdim)).to(device)\n",
    "        traj, t_test, normed_x_anchor  = DLPG.exploit(z=z, c=c, goal_position=goal_position)\n",
    "        normed_x_anchor                = normed_x_anchor.reshape(-1)\n",
    "        x_anchor                       = DLPG.scale_up(normed_x_anchor) # Store it into the buffer \n",
    "        # Solve IK \n",
    "        q_trajs  = []\n",
    "        for _, (x, y) in enumerate(zip(t_test, traj)):\n",
    "            print(f\"Exploit: (x_trgt, y_trgt, z_trgt): ({x}, {y}, {0.9})\")\n",
    "            q = env.solve_ik(\n",
    "                body_name=body_name, p_trgt=np.array([x[0], y[0], 0.9]), R_trgt=R_trgt, IK_P=True, IK_R=True,\n",
    "                q_init=init_configurations, idxs_forward=env.idxs_forward, idxs_jacobian=env.idxs_jacobian,\n",
    "                RESET=False, DO_RENDER=False, render_every=1, th=1*np.pi/180.0, err_th=1e-4)\n",
    "            # Make a trajectory by adding q values in every step.\n",
    "            # q = env.solve_ik(P_EE_des=np.array([x, y, 0.9], dtype=object), \n",
    "            #                     R_EE_des=np.array([-math.pi, 0, math.pi], dtype=object))\n",
    "            q_trajs.append(q)        \n",
    "            # Target position\n",
    "            goal = np.array([x, y, 0.9], dtype=object)\n",
    "            # Interpolation \n",
    "            interpoled_q_traj = DLPG.grp.interpolation(x_anchor=q_trajs, num_interpol=5)    \n",
    "            # Render \n",
    "            collision = env.execute_arm(q_des_lst    = interpoled_q_traj, \n",
    "                                        gripper_mode = \"open\", \n",
    "                                        goal         = goal, \n",
    "                                        obs_pose_lst = random_obs, \n",
    "                                        RENDER       = RENDER)\n",
    "            reward = DLPG.get_reward(collision, normed_x_anchor, random_obs, goal_position) \n",
    "            buffer.store(x=x_anchor.reshape(-1), c=c, reward=reward)        \n",
    "    # Explore [Prior sampling]\n",
    "    else: \n",
    "        # trajs, t_test = DLPG.random_explore(n_sample=n_sample, goal_position=goal_position)\n",
    "        trajs, t_test = DLPG.random_explore(n_sample=n_sample)\n",
    "        # Solve IK \n",
    "        for traj in trajs:\n",
    "            q_trajs  = []\n",
    "            normed_x_anchor = traj[5:7] # Fix index, To sample a point around a position of the target object.\n",
    "            x_anchor        = DLPG.scale_up(normed_x_anchor) # Store it into the buffer \n",
    "            for _, (x, y) in enumerate(zip(t_test, traj)):\n",
    "                print(f\"Explore: (x_trgt, y_trgt, z_trgt): ({x}, {y}, {0.9})\")\n",
    "                q = env.solve_ik(\n",
    "                    body_name=body_name, p_trgt=np.array([x[0], y[0], 0.9]), R_trgt=R_trgt, IK_P=True, IK_R=True,\n",
    "                    q_init=init_configurations, idxs_forward=env.idxs_forward, idxs_jacobian=env.idxs_jacobian,\n",
    "                    RESET=False, DO_RENDER=False, render_every=1, th=1*np.pi/180.0, err_th=1e-4)\n",
    "                # Make a trajectory by adding q values in every step.\n",
    "                # q = env.solve_ik(P_EE_des=np.array([x, y, 0.9], dtype=object), \n",
    "                #                     R_EE_des=np.array([-math.pi, 0, math.pi], dtype=object))\n",
    "                q_trajs.append(q)\n",
    "            # Target position\n",
    "            goal = np.array([x, y, 0.9], dtype=object)\n",
    "            # Interpolation \n",
    "            interpoled_q_traj = DLPG.grp.interpolation(x_anchor=q_trajs, num_interpol=5)    \n",
    "            # Render \n",
    "            collision = env.execute_arm(q_des_lst    = interpoled_q_traj, \n",
    "                                        gripper_mode = \"open\", \n",
    "                                        goal         = goal, \n",
    "                                        obs_pose_lst = random_obs, \n",
    "                                        RENDER       = RENDER)\n",
    "            reward = DLPG.get_reward(collision, normed_x_anchor, random_obs, goal_position) \n",
    "            buffer.store(x=x_anchor.reshape(-1), c=c_np, reward=reward)\n",
    "    \"\"\" UPDATE \"\"\"\n",
    "    loss_recon_sum=0;loss_kl_sum=0;n_batch_sum=0\n",
    "    if (epoch+1)%update_every==0 and (epoch+1)>99:\n",
    "        for it in range(MAXITER):\n",
    "            if it >= 30: beta = 10 # Heuristic \n",
    "            else:        beta = 0.0\n",
    "            batch = buffer.sample_batch(sample_method=sample_method, batch_size=batch_size)\n",
    "            x_batch, c_batch, reward_batch = batch[\"x\"], batch[\"c\"], batch[\"reward\"]\n",
    "            total_loss_out,loss_info = DLPG.cvae.loss_total(x               = x_batch, \n",
    "                                                            c               = c_batch, \n",
    "                                                            q               = reward_batch, \n",
    "                                                            LOSS_TYPE       = 'L1+L2',\n",
    "                                                            recon_loss_gain = 1,\n",
    "                                                            beta            = beta,\n",
    "                                                            STOCHASTICITY   = True)\n",
    "            optimizer.zero_grad()\n",
    "            total_loss_out.backward()\n",
    "            optimizer.step()\n",
    "            n_batch        = x_batch.shape[0]\n",
    "            loss_recon_sum = loss_recon_sum + n_batch*loss_info['loss_recon_out']\n",
    "            loss_kl_sum    = loss_kl_sum + n_batch*loss_info['loss_kl_out']\n",
    "            n_batch_sum    = n_batch_sum + n_batch\n",
    "        # Average loss during train\n",
    "        loss_recon_avg, loss_kl_avg = (loss_recon_sum/n_batch_sum),(loss_kl_sum/n_batch_sum)\n",
    "        # Print\n",
    "        print (\"[%d/%d] DLPG updated. Total loss:[%.3f] (recon:[%.3f] kl:[%.3f])\"%\n",
    "            (epoch+1,max_epochs,loss_recon_avg+loss_kl_avg,loss_recon_avg,loss_kl_avg))\n",
    "        if WANDB:\n",
    "            wandb.log({\"Total loss\":loss_recon_avg+loss_kl_avg,\n",
    "                        \"recon_loss\":loss_recon_avg,\n",
    "                        \"kl_loss\":loss_kl_avg}, step=epoch+1)   \n",
    "        # Save weights         \n",
    "        torch.save(DLPG.cvae.state_dict(),\"weights\"+\"/\"+str(runname)+\"/{}steps.pth\".format(epoch+1))    \n",
    "        \"\"\" EVALUATE \"\"\"\n",
    "        eval_reward=0\n",
    "        plt.figure(figsize=(6,9))\n",
    "        with torch.no_grad():\n",
    "            for it in range(eval_epochs):\n",
    "                env.reset()\n",
    "                # Random spawn \n",
    "                goal_position  = np.random.uniform(-0.1, 0.1) \n",
    "                random_obs = env.random_pose(goal_position=goal_position)\n",
    "                # Get a conditional vector\n",
    "                c_np           = np.array(random_obs).reshape(-1)\n",
    "                c_np           = np.append(c_np, goal_position)  \n",
    "                c              = np2torch(c_np, device=device).reshape(1,-1)\n",
    "                z              = torch.randn(size=(1, DLPG.zdim)).to(device)\n",
    "                traj, t_test, normed_x_anchor = DLPG.exploit(z=z, \n",
    "                                                                c=c, \n",
    "                                                                goal_position=goal_position)   \n",
    "                normed_x_anchor = normed_x_anchor.reshape(-1)\n",
    "                # Solve IK \n",
    "                q_trajs  = []\n",
    "                for _, (x, y) in enumerate(zip(t_test, traj)):\n",
    "                    # Make a trajectory by adding q values in every step.\n",
    "                    q = env.solve_ik(P_EE_des=np.array([x, y, 0.9], dtype=object), \n",
    "                                        R_EE_des=np.array([-math.pi, 0, math.pi], dtype=object))\n",
    "                    q_trajs.append(q)\n",
    "                # Target position\n",
    "                goal = np.array([x, y, 0.9], dtype=object)\n",
    "                # Interpolation \n",
    "                interpoled_q_traj = DLPG.grp.interpolation(x_anchor=q_trajs, num_interpol=10)    \n",
    "                # Render \n",
    "                collision = env.execute_arm(q_des_lst    = interpoled_q_traj, \n",
    "                                            gripper_mode = \"open\", \n",
    "                                            goal         = goal, \n",
    "                                            obs_pose_lst = random_obs, \n",
    "                                            RENDER       = RENDER)\n",
    "                reward    = DLPG.get_reward(collision, normed_x_anchor, random_obs, goal_position)  \n",
    "                eval_reward+=reward\n",
    "                # Demonstration for exploitation samples\n",
    "                plt.ylim(-0.45, 0.45)\n",
    "                plt.xlim(0.5,0.9)\n",
    "                plt.title(\"Exploit samples[Epoch{}]\".format(epoch), fontsize=20)\n",
    "                plt.xlabel(\"X axis\", fontsize=15)\n",
    "                plt.ylabel(\"Y axis\", fontsize=15)\n",
    "                plt.scatter(0.65, normed_x_anchor[0], s=50) \n",
    "                plt.scatter(0.8,  normed_x_anchor[1], s=50)\n",
    "            plt.savefig(\"data/exploit_samples{}.png\".format(epoch+1))\n",
    "            # Print\n",
    "            if WANDB: wandb.log({\"Reward\":eval_reward/eval_epochs}, step=epoch+1)   \n",
    "            print(\"[Evaluate Reward]:{}\".format(eval_reward/eval_epochs))\n",
    "    print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
